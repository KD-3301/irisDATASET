import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

df = pd.read_csv('/content/Iris.csv')
df.head()

df.describe()

df.isnull().sum()

d = {
    'Iris-setosa':0,
    'Iris-versicolor':1,
    'Iris-virginica':2
}
df['Species'] = df['Species'].map(d)
df

df = df.drop(['Id'],axis = 1)
df

df_species = df["Species"]
df_species

df = df.drop(['Species'],axis = 1)
df.head()

plt.figure(figsize = (15,8))
plt.subplot(1,2,1)
plt.scatter(df['SepalLengthCm'],df['SepalWidthCm'],s = 100,c = 'blue')
plt.xlabel('SepalLength(Cm)')
plt.ylabel('Sepalwidth(Cm)')

plt.subplot(1,2,2)
plt.scatter(df['PetalLengthCm'],df['PetalWidthCm'],s = 100, c='blue')
plt.scatter(df['PetalLengthCm'],df['PetalWidthCm'],s = 100,c = 'blue')
plt.xlabel('PetalLength(Cm)')
plt.ylabel('Petalwidth(Cm)')
plt.show()

X = df.iloc[:,:]
X.head()

from sklearn.cluster import KMeans
wcss = []
for i in range(1,11):
  kmeans = KMeans(n_clusters = i, init = 'k-means++',random_state = 6)
  kmeans.fit(X)
  wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of cluster')
plt.ylabel('WCSS')
plt.show()

kmeans = KMeans(n_clusters = 3,init = 'k-means++',random_state = 6)
y_kmeans = kmeans.fit_predict(X)
print(y_kmeans)

plt.scatter(X[y_kmeans == 0]['PetalLengthCm'],X[y_kmeans == 0]['PetalWidthCm'],s=50,c='red',label='Iris Settosa')
plt.scatter(X[y_kmeans == 1]['PetalLengthCm'],X[y_kmeans == 1]['PetalWidthCm'],s=50,c='blue',label='Iris Versicolor')
plt.scatter(X[y_kmeans == 2]['PetalLengthCm'],X[y_kmeans == 2]['PetalWidthCm'],s=50,c='yellow',label='Iris Versicolor')
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=100,c = 'black',label = 'Centroids',alpha=0.7)
plt.show()


from sklearn.metrics import silhouette_score,adjusted_rand_score,jaccard_score,confusion_matrix

silhouette_score(X,y_kmeans)

adjusted_rand_score(df_species,y_kmeans)

jaccard_score(df_species,y_kmeans,average = 'macro')

def purity_score(y_true,y_pred):
  confusionmatrix = confusion_matrix(y_pred,y_true)
  return np.sum(np.amax(confusionmatrix/np.sum(confusionmatrix)))

purity_score(df_species,y_kmeans)

X = df.iloc[:,[0,1]]
X.head()

kmeans = KMeans(n_clusters = 3,init = 'k-means++',random_state = 6)
y_kmeans = kmeans.fit_predict(X)
print(y_kmeans)

plt.scatter(X[y_kmeans == 0]['SepalLengthCm'],X[y_kmeans == 0]['SepalWidthCm'],s=50,c='red',label='Iris Settosa')
plt.scatter(X[y_kmeans == 1]['SepalLengthCm'],X[y_kmeans == 1]['SepalWidthCm'],s=50,c='blue',label='Iris Versicolor')
plt.scatter(X[y_kmeans == 2]['SepalLengthCm'],X[y_kmeans == 2]['SepalWidthCm'],s=50,c='yellow',label='Iris Versicolor')
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=100,c = 'black',label = 'Centroids',alpha=0.7)
plt.show()


silhouette_score(X,y_kmeans)

#    DBscan :

from sklearn.cluster import DBSCAN
from sklearn import metrics

db = DBSCAN(eps = 0.3,min_samples = 10)
db.fit(X)
y_pred = db.fit_predict(X)

core_samples_mask = np.zeros_like(db.labels_,dtype=bool)
core_samples_mask

y_pred

core_samples_mask[db.core_sample_indices_] = True
core_samples_mask

labels = db.labels_

labels

plt.scatter(X['PetalLengthCm'],X['PetalWidthCm'], c = y_pred, cmap = "paired")
plt.show()

n_cluster = len(set(labels)) - (1 if -1 in labels else 0)
n_noise = list(labels).count(-1)

print('No. of cluster for Iris dataset = ', n_cluster)
print('No. of noise data sample in dataset =', n_noise)

db = DBSCAN(eps=0.5, min_samples = 10)
db.fit(X)
y_pred = db.fit_predict(X)
plt.scatter(X['SepalLengthCm'], X['SepalWidthCm'], c=y_pred, cmap = 'Paired')
plt.title("DBSCAN")

labels = db.labels_

n_cluster = len(set(labels)) - (1 if -1 in labels else 0)
n_noise = list(labels).count(-1)

print('No. of cluster for Iris dataset =',n_cluster)
print('No. of noise data sample in dataset=', n_noise)


#validation of cluster: 

silhouette_score(X,y_pred)

adjusted_rand_score(df_species,labels)

jaccard_score(df_species,labels,average='micro')

purity_score(df_species,labels)
